# -*- coding: utf-8 -*-
"""mnist_cnn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hJhjJAUhgKG2D81DtkwI6JwDfqBcsmpr
"""

# MNIST digit recognition using convolutiona neural networks
# Importing the required libraries
from keras.models import Sequential
from keras.layers import Conv2D
from keras.layers import MaxPooling2D
from keras.layers import Flatten
from keras.layers import Dense
import tensorflow.keras.datasets.mnist as mnist
from keras.utils import to_categorical
import numpy as np

0# Building the deep learning model
# This step involve two steps
# Step 1 : Feature Extraction using convolution and pooling layers alternatively
# Step 2 : Classification using a dense layer neural net layer

# Feature Extraction using Convolution and Pooling layers
model = Sequential()
# Convolutional layer 1
model.add(Conv2D(32, (5,5), 
                 strides = (1,1),
                 input_shape = (28,28,1),
                 activation = 'relu',
                 ))
# Pooling Layer 1
model.add(MaxPooling2D((2,2)))
# Convolutional layer 2
model.add(Conv2D(64, (5,5),
                 strides = (1,1),
                 activation = 'relu',
                 ))
# Pooling layer 2
model.add(MaxPooling2D((2,2)))

# Classification using dense neural network
model.add(Flatten())
model.add(Dense(64, activation = 'relu'))
model.add(Dense(10, activation ='softmax'))

# Partitioning the dataset into training set and test set
(train_images, train_labels), (test_images, test_labels) = mnist.load_data()
train_images = train_images.reshape((60000, 28,28,1))
test_images  = test_images.reshape((10000,28,28,1))

# Normalization of data
train_images = (train_images / 255)
test_images  = (test_images / 255)

# One hot encoding of the labels
train_labels = to_categorical(train_labels)
test_labels  = to_categorical(test_labels)

# Training the neural network
model.compile(
    optimizer = 'adam',
    loss = 'categorical_crossentropy',
    metrics = ['accuracy'])

model.fit(train_images,
          train_labels,
          batch_size = 16,
          epochs = 5)

# Evaluating tghe model using the test set
model.evaluate(test_images,
               test_labels)

# Making predictions
predictions = model.predict(test_images[:15])
print(np.argmax(predictions,axis = 1))

